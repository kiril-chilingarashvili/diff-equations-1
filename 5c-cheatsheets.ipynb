{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c5f6352-4145-4a2f-8896-5141dd075e3d",
   "metadata": {},
   "source": [
    "# Unit 5: Nonlinear DEs - Part c: Numerical methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abd7363-9539-425c-93ac-1824b2d36aa1",
   "metadata": {},
   "source": [
    "## 2. Euler's method\n",
    "\n",
    "### Consider an ODE $\\dot{y} = f(t, y)$. It specifies a slope field in the $(t, y)$-plane, and solution curves follow the slope field.\n",
    "\n",
    "### Suppose that we are given a starting point $(t_0, y_0)$ and that we are trying to approximate the solution curve through it.\n",
    "\n",
    "### ***Question 2.1***\n",
    "### Where, approximately, will be the point on the solution curve at a time $h$ seconds later?\n",
    "\n",
    "### ***Solution***\n",
    "### We have $y(t_0) = y_0$ and $y'(t_0) = f(t_0, y_0)$. Using linear approximation, we get\n",
    "## $$ y(t_0 + h) = y_0 + h f(t_0, y_0) $$\n",
    " \n",
    "### The geometrical picture as follows:\n",
    "![img](img/sc38.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be052b7-05d9-4e14-bae3-cc407d5b6210",
   "metadata": {},
   "source": [
    "### Consider again the ODE $\\dot{y} = f(t, y)$ and the starting point $(t_0, y_0)$. We try to approximate the solution curve through it.\n",
    "\n",
    "### ***Question 2.2***\n",
    "### Where, approximately, will be the point on the solution curve at time $t_0 + 3h$?\n",
    "\n",
    "### ***Solution***\n",
    "### The crude answer would be to take $3$ steps each using the initial slope $f(t_0, y_0)$ (or equivalently, one big step of width $3h$).\n",
    "\n",
    "### Geometrically:\n",
    "![img](img/sc39.png)\n",
    " \n",
    "### The more refined answer is called ***Euler's method***: take $3$ steps, ***but reassess the slope after each step, using the slope field at each successive position***:\n",
    "![img](img/sc40.png)\n",
    "\n",
    "## $$ \\begin{array} {rcl} t_1 = t_0 + h & & y_1 = y_0 + f(t_0, y_0) h \\\\ t_2 = t_1 + h & & y_2 = y_1 + f(t_1, y_1) h \\\\ t_3 = t_2 + h & & y_3 = y_2 + f(t_2, y_2) h \\end{array} $$\n",
    "\n",
    "### The sequence of line segments from $(t_0, y_0)$ to $(t_1, y_1)$ to $(t_2, y_2)$ to $(t_3, y_3)$ is a piecewise linear approximation to the solution curve. The more refined answer to the question is $(t_3, y_3)$\n",
    "\n",
    "### ***Euler's Method***:\n",
    "\n",
    "### Given an initial value problem\n",
    "## $$ y' = f(t, y) \\quad y(t_0) = y_0 $$\n",
    "\n",
    "### and a choice of ***step size*** $h$ (in seconds if time is the independent variable), the Euler method gives an approximation to the solution curve between $t=t_0$ and $t=t_0 + (n+1)h$ by a sequence of line segments connecting the points $(t_0, y_0), (t_1, y_1), \\ldots,(t_n, y_n), (t_{n+1}, y_{n+1})$, where for each $0 \\leq k \\leq n$\n",
    "## $$ \\begin{array} {rcl} t_{k+1} & = & t_k + h \\\\ y_{k+1} & = & y_k + h f(t_k, y_k) \\end{array} $$\n",
    "![img](img/sc41.png)\n",
    "\n",
    "### These calculations are usually done by computer, and there are round-off errors in calculations. But even if there are no round-off errors, Euler's method hardly ever gives the exact answer. The problem is that the actual solution is rarely a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a661bf0b-ca39-45de-85f6-7c04ce0f1d87",
   "metadata": {},
   "source": [
    "## 3. Overestimate, underestimate and concavity\n",
    "\n",
    "### One of the first questions to ask about the Euler method is whether the approximation it gives is too high or too low. This is in general difficult to decide, but when the actual solution is known to be either concave or convex, we do know the answer.\n",
    "\n",
    "### Recall in Euler's method, we start with the initial value problem\n",
    "## $$ y' = f(t, y) \\quad y(t_0) = y_0 $$\n",
    "\n",
    "### Let $y(t)$ be the actual solution and let $\\overline{y}(t)$ be the approximate solution given by Euler's method with stepsize $h$. As before, $t_n = t_0 + nh$ is the time after $n$ steps.\n",
    "\n",
    "### - If $y(t)$ is ***convex*** (or ***concave up***), that is, if $\\ddot{y} > 0$ in the interval $[t_0, t_n]$, and in a region along the Euler polygon $\\overline{y}(t)$, then $\\overline{y}(t_n) < y(t_n)$.\n",
    "![img](img/sc42.png)\n",
    "\n",
    "### - If $y(t)$ is ***concave*** (or ***concave down***), that is, if $\\ddot{y} < 0$, in the interval $[t_0, t_n]$, and in a region along the Euler polygon $\\overline{y}(t)$, then $\\overline{y}(t_n) > y(t_n)$.\n",
    "![img](img/sc43.png)\n",
    "\n",
    "### Often we do not know whether the actual solution $y(t)$ is convex or concave in an entire interval. What we are able to compute without knowledge of the solution is the value of $\\ddot{y}$ at the starting point $t_0$. This is still useful because this means that as long as we carry out Euler's method for a short enough time interval, we can still predict whether the Euler approximation overshoots or undershoots.\n",
    "\n",
    "### To find $\\ddot{y}$ at the starting point $t_0$ we differentiate the DE $\\dot{y} = f(t, y)$ to find $\\ddot{y}$. The differentiation is often called implicit because the variable $y$ depends on $t$. This gives us a formula for $\\ddot{y}$ in terms of $t, y$ and $\\dot{y}$ To evaluate $\\ddot{y}(t)$ plug in the initial condition $t_0, y(t_0)$ as well as $\\dot{y}(t_0) = f(t_0, y_0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02449750-cd47-4b94-9e97-98333a1cba6d",
   "metadata": {},
   "source": [
    "## 4. Error and step size\n",
    "\n",
    "### To improve the approximation by the Euler method, we can use a smaller step size $H$, so that the slopes of the line segments are reassessed more frequently.\n",
    "\n",
    "### The cost of this, however, is that to increase $T$ by a fixed amount, more steps will be needed.\n",
    "\n",
    "### Under reasonable hypotheses on $F$ – the right hand side of the DE $\\dot{y} = f(t, y)$ – one can prove that in the limit as $h\\to 0$, this process converges and produces an exact solution curve. This is one way to prove that the solution to the initial value problem exists. In fact, this is the way Euler proved it.\n",
    "\n",
    "### ***Error of approximation***:\n",
    "### Let $\\overline{y}(t)$ be the approximate solution given by Euler's method with step size $h$\n",
    "\n",
    "### Let the ***error of approximation*** $e$ over the interval $[a, b]$ be\n",
    "## $$ e = \\max_{a \\leq t \\leq b} |y(t) - \\overline{y}(t)| $$\n",
    " \n",
    "### That is, $e$ is the maximum absolute difference between the actual solution $y(t)$ and $\\overline{y}(t)$. The error $e$ is bounded above by a ***linear*** function of $h$\n",
    "## $$ e \\leq Ch $$\n",
    "\n",
    "### where $C$ is a constant depending on $f$. Because $h$ occurs as a first power above, not $h^{1/2}$ or $h^2$, Euler's method is called a ***first order method***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9f8a20-cb32-4f60-b35e-fbb2db7e6735",
   "metadata": {},
   "source": [
    "## 5. Euler's Method mathlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30c7785-827a-4d91-90cb-bac59fbba98e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"900\" height=\"650\" src=\"https://1803mathlets.netlify.app/eulersmethod\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe width=\"900\" height=\"650\" src=\"https://1803mathlets.netlify.app/eulersmethod\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af86c0-b6e6-4986-8fca-42bdf958ee2c",
   "metadata": {},
   "source": [
    "## 7. Reliability\n",
    "\n",
    "### ***Question 7.1***\n",
    "### How can we decide whether answers obtained numerically can be trusted?\n",
    "\n",
    "### Here are some heuristic tests. (“Heuristic\" means that loosely speaking, these tests work in practice, but they are not proved to work always.)\n",
    "\n",
    "### - ***Self-consistency***: \n",
    "### Solution curves should not cross! If numerically computed solution curves cross, a smaller step size is needed. (E.g., try the mathlet “Euler's Method\" with $y' = y^2 - x$, step size $1$, and starting points $(0, 0)$ and $(0, 1/2)$.)\n",
    "\n",
    "### - ***Convergence as $h\\to 0$***:\n",
    "### The estimate for $y(t)$ at a fixed later time $t$ should converge to the true value as $h\\to 0$. If shrinking $h$ causes the estimate to change a lot, then $h$ is probably not small enough yet. (E.g., try the mathlet “Euler's Method\" with $y' = y^2 - x$ with starting point $(0, 0)$ and various step sizes.)\n",
    "\n",
    "### - ***Structural stability***:\n",
    "### Small changes in the DE's parameters should not change the outcome completely. If small changes in the parameters drastically change the outcome, the answer should not be trusted.\n",
    "\n",
    "### - ***Stability***:\n",
    "### Small changes in the DE's initial conditions do not change the outcome much. One reason for instability could be a separatrix, a curve such that nearby starting points on different sides lead to qualitatively different outcomes; this is not a fault of the numerical method, but rather an instability in the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179ac27-975f-44eb-9394-ca3a1caa73c2",
   "metadata": {},
   "source": [
    "## 8. Change of variable\n",
    "\n",
    "### Euler's method generally can't be trusted to give reasonable values when $(t, y)$ strays very far from the starting point. In particular, the solutions it produces usually deviate from the truth as $t \\to \\pm \\infty$, or in situations in which $y \\to \\pm \\infty$ in finite time. Anything that goes off the screen can't be trusted.\n",
    "\n",
    "### ***Example 8.1***\n",
    "### The solution to $\\dot{y} = y^2 - t$ starting at $(-2, 1)$ seems to go to $+\\infty$ in finite time. But Euler's method never produces a value of $+\\infty$.\n",
    "\n",
    "### To see what is really happening in this example, try the ***change of variable*** $\\displaystyle u = \\frac{1}{y}$. To rewrite the DE in terms of $u$, substitute $\\displaystyle y = \\frac{1}{u}$ and $\\displaystyle \\dot{y} = -\\frac{\\dot{u}}{u^2}$:\n",
    "## $$ \\begin{array} {rcl} \\displaystyle -\\frac{\\dot{u}}{u^2} & = & \\displaystyle \\frac{1}{u^2} - t \\\\ \\dot{u} & = & -1 + t u^2 \\end{array} $$\n",
    "\n",
    "### This is equivalent to the original DE, but now, when $y$ is large, $u$ is small, and Euler's method can be used to find the time when $u$ crosses $0$, which is when $y$ blows up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07d1d4-1c12-4551-b5f9-8e9d2ee313f1",
   "metadata": {},
   "source": [
    "## 9. Runge–Kutta methods\n",
    "\n",
    "### When computing $\\displaystyle \\int_{a}^{b} f(t) dt$ numerically, the most primitive method is to use the left Riemann sum: divide the range of integration into subintervals of width $h$, and estimate the value of $f(t)$ for each $t$ on the subinterval by the value at the left endpoint. More sophisticated methods are the ***trapezoid rule*** and ***Simpson's rule***, which have smaller errors.\n",
    "\n",
    "### There are analogous improvements to Euler's method.\n",
    "## $$ \\begin{array} {rcl} \\text{Integration} & \\text{Differential equation} & \\text{Error} \\\\ \\text{left Riemann sum} & \\text{Euler's method} & O(h) \\\\ \\text{trapezoid rule} & \\text{second-order Runge–Kutta method (RK2)} & O(h^2) \\\\ \\text{Simpson's rule} & \\text{fourth-order Runge–Kutta method (RK4)} & O(h^4) \\end{array} $$\n",
    "\n",
    "### The ***big $O$ notation*** $O(h^4)$ means that there is a constant $C$ (depending on the differential equation but not on $h$) such that the error is at most $C h^4$, assuming that $h$ is small. The error estimates in the table are valid for reasonable differential equations.\n",
    "\n",
    "### ***Better methods***:\n",
    "\n",
    "### The Runge–Kutta methods evaluate at more points on the interval $[t_0, t_0 + h]$ to get a better estimate of what happens to the slope over the course of that interval.\n",
    "\n",
    "### Below is an example of a ***second-order Runge–Kutta method (RK2)***.\n",
    "### It is also called the ***midpoint method*** or the ***modified Euler method***.\n",
    "\n",
    "### Here is how one step of this method goes:\n",
    "![img](img/sc44.png)\n",
    " \n",
    "### 1. Starting from $(t_0, y_0$, look ahead to see where one step of Euler's method would land, but do not go there! Call this temporary point $(t_1, \\tilde{y}_1)$ \n",
    "\n",
    "### 2. Find the ***midpoint*** between the starting point and the temporary point: $\\displaystyle \\left( \\frac{t_0 + t_1}{2}, \\frac{y_0 + \\tilde{y}_1}{2} \\right)$\n",
    "\n",
    "### 3. Use the slope at this midpoint to find $y_1$\n",
    "## $$ y_1 = y_0 + h f \\left( \\frac{t_0 + t_1}{2}, \\frac{y_0 + \\tilde{y}_1}{2} \\right) $$\n",
    " \n",
    "### Repeat the steps above using $t_1, h_1$ as the starting point.\n",
    "\n",
    "### Here is a summary of the equations:\n",
    "## $$ \\begin{array} {rcl} t_1 & = & t_0 + h \\\\ \\tilde{y}_1 & = & y_0 + h f (t_0, y_0) \\\\ y_1 & = & \\displaystyle y_0 + h f \\left( \\frac{t_0 + t_1}{2}, \\frac{y_0 + \\tilde{y}_1}{2} \\right) \\\\ (t_0, y_0) & \\mapsto & (t_1, y_1)  \\end{array} $$\n",
    "\n",
    "### ***Even better methods***:\n",
    "\n",
    "### The ***fourth-order Runge–Kutta method (RK4)*** is similar, but more elaborate, averaging several slopes. It is the most commonly used method for solving DEs numerically. Some people simply call it ***the*** Runge–Kutta method. The mathlets we have been playing with use RK4 with a small step size to compute the “actual\" solution to a DE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34cca85-100a-4946-9f00-cb1048e95d15",
   "metadata": {},
   "source": [
    "## 10. Software\n",
    "\n",
    "### Most software systems have numerical routines that are built in. Many of these numerical routines use variable order methods. You may want to check some out, and play around with them. Make sure that you check the documentation for how to enter the arguments of each method.\n",
    "\n",
    "### ***Maple***\n",
    "\n",
    "### - Euler(ODE, IC, t=b, opts)\n",
    "### - RungeKutta(ODE, IC, t=b, opts)\n",
    "\n",
    "### ***MATLAB***\n",
    "\n",
    "### - ode45(odefunc,tspan,y0,options)\n",
    "### - ode23(odefunc,tspan,y0,options)\n",
    "### - ode113(odefunc,tspan,y0,options)\n",
    "\n",
    "### ***Python (scipy.integrate)***\n",
    "\n",
    "### - odeint(func,y0,t,args=())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defc0cd0-e046-4f5c-a2a2-66085be0a45a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
